{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies :-\n",
    "Download Java 64 bit version.\n",
    "https://www.java.com/en/download/\n",
    "\n",
    "pip install requests\n",
    "\n",
    "pip install tabulate\n",
    "\n",
    "pip install \"colorama>=0.3.8\"\n",
    "\n",
    "pip install future\n",
    "\n",
    "pip uninstall h2o\n",
    "\n",
    "pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) Client VM (build 25.251-b08, mixed mode, sharing)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham Arrora\\AppData\\Roaming\\Python\\Python36\\site-packages\\h2o\\backend\\server.py:385: UserWarning:   You have a 32-bit version of Java. H2O works best with 64-bit Java.\n",
      "  Please download the latest 64-bit Java SE JDK from Oracle.\n",
      "\n",
      "  warn(\"  You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting server from C:\\Users\\Shubham Arrora\\AppData\\Roaming\\Python\\Python36\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\tmp5_xb2ong\n",
      "  JVM stdout: C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\tmp5_xb2ong\\h2o_Shubham_Arrora_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\tmp5_xb2ong\\h2o_Shubham_Arrora_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>14 days, 3 hours and 18 minutes </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Shubham_Arrora_ovtwuc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>247.5 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         05 secs\n",
       "H2O_cluster_timezone:       Asia/Kolkata\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.4\n",
       "H2O_cluster_version_age:    14 days, 3 hours and 18 minutes\n",
       "H2O_cluster_name:           H2O_from_python_Shubham_Arrora_ovtwuc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    247.5 Mb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.5 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Import a sample binary outcome train/test set into H2O\n",
    "train = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv\")\n",
    "test = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"response\"\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CV folds (to generate level-one data for stacking)\n",
    "nfolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a few ways to assemble a list of models to stack together:\n",
    "# 1. Train individual models and put them in a list\n",
    "# 2. Train a grid of models\n",
    "# 3. Train several grids of models\n",
    "# Note: All base models must have the same cross-validation folds and\n",
    "# the cross-validated predicted values must be kept.\n",
    "\n",
    "# 1. Generate a 2-model ensemble (GBM + RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and cross-validate a GBM\n",
    "my_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\",\n",
    "                                      ntrees=10,\n",
    "                                      max_depth=3,\n",
    "                                      min_rows=2,\n",
    "                                      learn_rate=0.2,\n",
    "                                      nfolds=nfolds,\n",
    "                                      fold_assignment=\"Modulo\",\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1)\n",
    "my_gbm.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and cross-validate a RF\n",
    "my_rf = H2ORandomForestEstimator(ntrees=50,\n",
    "                                 nfolds=nfolds,\n",
    "                                 fold_assignment=\"Modulo\",\n",
    "                                 keep_cross_validation_predictions=True,\n",
    "                                 seed=1)\n",
    "my_rf.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
      "Best Base-learner Test AUC:  0.7697982150254795\n",
      "Ensemble Test AUC:  0.7735371695404032\n"
     ]
    }
   ],
   "source": [
    "# Train a stacked ensemble using the GBM and GLM above\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_binomial\",\n",
    "                                       base_models=[my_gbm, my_rf])\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)\n",
    "\n",
    "# Compare to base learner performance on the test set\n",
    "perf_gbm_test = my_gbm.model_performance(test)\n",
    "perf_rf_test = my_rf.model_performance(test)\n",
    "baselearner_best_auc_test = max(perf_gbm_test.auc(), perf_rf_test.auc())\n",
    "stack_auc_test = perf_stack_test.auc()\n",
    "print(\"Best Base-learner Test AUC:  {0}\".format(baselearner_best_auc_test))\n",
    "print(\"Ensemble Test AUC:  {0}\".format(stack_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# 2. Generate a random grid of models and stack them together\n",
    "\n",
    "# Specify GBM hyperparameters for the grid\n",
    "hyper_params = {\"learn_rate\": [0.01, 0.03],\n",
    "                \"max_depth\": [3, 4, 5, 6, 9],\n",
    "                \"sample_rate\": [0.7, 0.8, 0.9, 1.0],\n",
    "                \"col_sample_rate\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "search_criteria = {\"strategy\": \"RandomDiscrete\", \"max_models\": 3, \"seed\": 1}\n",
    "\n",
    "# Train the grid\n",
    "grid = H2OGridSearch(model=H2OGradientBoostingEstimator(ntrees=10,\n",
    "                                                        seed=1,\n",
    "                                                        nfolds=nfolds,\n",
    "                                                        fold_assignment=\"Modulo\",\n",
    "                                                        keep_cross_validation_predictions=True),\n",
    "                     hyper_params=hyper_params,\n",
    "                     search_criteria=search_criteria,\n",
    "                     grid_id=\"gbm_grid_binomial\")\n",
    "grid.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
      "Best Base-learner Test AUC:  0.748146530400473\n",
      "Ensemble Test AUC:  0.7510921003414699\n"
     ]
    }
   ],
   "source": [
    "# Train a stacked ensemble using the GBM grid\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_gbm_grid_binomial\",\n",
    "                                       base_models=grid.model_ids)\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)\n",
    "\n",
    "# Compare to base learner performance on the test set\n",
    "baselearner_best_auc_test = max([h2o.get_model(model).model_performance(test_data=test).auc() for model in grid.model_ids])\n",
    "stack_auc_test = perf_stack_test.auc()\n",
    "print(\"Best Base-learner Test AUC:  {0}\".format(baselearner_best_auc_test))\n",
    "print(\"Ensemble Test AUC:  {0}\".format(stack_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
